# LearningAgent Configuration
# Edit this file to adjust behavior without changing code

# Model settings
model: qwen3:4b  # For Ollama models like "qwen3:4b"
model_provider: "ollama"  # Options: "ollama" or "openrouter"
openrouter_model: "deepseek/deepseek-prover-v2:free"  # Only used when model_provider is "openrouter"
temperature: 0.3

# Memory
use_memory: false

# Embedding
embedding_model: BAAI/bge-small-en-v1.5

# Retrieval settings
top_k: 8
similarity_threshold: 0.5

# Chunking settings
chunk_size: 10000
chunk_overlap: 500

# Web search fallback
use_web_fallback: false
web_results: 3

# Collection name
collection: MoravaKTheory

# Response formatting
use_latex_rendering: true
prompt_template: "Answer the question based on the following context. \nIf you don't know the answer, just say you don't know; don't make up information.\nFor mathematical expressions, use LaTeX notation with proper delimiters (\\( \\) for inline math and \\[ \\] for display math).\n\nContext:\n{context}\n\nQuestion: {question}\n"
